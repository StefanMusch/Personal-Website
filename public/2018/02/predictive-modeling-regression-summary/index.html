

  
    
  


  





  

<!DOCTYPE html>
<link rel="stylesheet" href="/css/hybrid.css" rel="stylesheet" id="theme-stylesheet">
<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<html lang="en-us">
  <head>
  
    
	
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.46 with theme Tranquilpeak 0.4.3-BETA">
    <title>Predictive Modeling - Regression Summary</title>
    <meta name="author" content="Stefan Musch">
    <meta name="keywords" content=", Data Science, Data Blog, R Markdown, R Visualisation">

    <link rel="icon" href="/favicon.png">
    

    
    <meta name="description" content="A comprehensive summary of predictive modeling with regression techniques. Inspired by a lecture given by Sandjai Bhulai, who is a Professor at the Free University of Amsterdam and co-founder of the postgraduate programme Business Analytics / Data Science">
    <meta property="og:description" content="A comprehensive summary of predictive modeling with regression techniques. Inspired by a lecture given by Sandjai Bhulai, who is a Professor at the Free University of Amsterdam and co-founder of the postgraduate programme Business Analytics / Data Science">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Predictive Modeling - Regression Summary">
    <meta property="og:url" content="/2018/02/predictive-modeling-regression-summary/">
    <meta property="og:site_name" content="S. Musch">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="S. Musch">
    <meta name="twitter:description" content="A comprehensive summary of predictive modeling with regression techniques. Inspired by a lecture given by Sandjai Bhulai, who is a Professor at the Free University of Amsterdam and co-founder of the postgraduate programme Business Analytics / Data Science">
    
      <meta name="twitter:creator" content="@Stefan_Musch">
    
    

    
    

    
      <meta property="og:image" content="http://res.cloudinary.com/stefanmusch/image/upload/c_scale,w_725/v1534148918/thumbnail/headshot2.jpg">
    

    
      <meta property="og:image" content="http://res.cloudinary.com/stefanmusch/image/upload/v1518948709/thumbnail/regression.png">
    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-111116966-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">S. Musch</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="http://res.cloudinary.com/stefanmusch/image/upload/c_scale,w_725/v1534148918/thumbnail/headshot2.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="http://res.cloudinary.com/stefanmusch/image/upload/c_scale,w_725/v1534148918/thumbnail/headshot2.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Stefan Musch</h4>
        
          <h5 class="sidebar-profile-bio">Data Scientist | Marketing Analyst |<br> Music, Sports &amp; Adventure Enthousiast <br> <br> This blog is the place where I share my work, projects, frustrations and discoveries. I designed it to be entertaining to some, and educative to others. Sometimes hopefully both. <br><br>Enjoy reading, and feel free to leave a comment!</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/page/curriculum-vitae">
    
      <i class="sidebar-button-icon fa fa-lg fa-graduation-cap"></i>
      
      <span class="sidebar-button-desc">CV</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/page/contact">
    
      <i class="sidebar-button-icon fa fa-lg fa-envelope"></i>
      
      <span class="sidebar-button-desc">Contact</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/StefanMusch">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.linkedin.com/in/stefanmusch/">
    
      <i class="sidebar-button-icon fa fa-lg fa-linkedin-square"></i>
      
      <span class="sidebar-button-desc">LinkedIn</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.r-bloggers.com">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">R-Bloggers</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Predictive Modeling - Regression Summary
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-02-14T00:00:00Z">
        
  
  
  
  
    14 February 2018
  

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/professional-projects">Professional Projects</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#packages-and-initialisations"><span class="toc-section-number">2</span> Packages and initialisations</a></li>
<li><a href="#exploratory-data-analysis-eda"><span class="toc-section-number">3</span> Exploratory Data Analysis (EDA)</a><ul>
<li><a href="#missing-values"><span class="toc-section-number">3.1</span> Missing Values</a></li>
<li><a href="#discrete-variables"><span class="toc-section-number">3.2</span> Discrete Variables</a></li>
<li><a href="#continuous-variables"><span class="toc-section-number">3.3</span> Continuous Variables</a></li>
<li><a href="#correlations"><span class="toc-section-number">3.4</span> Correlations</a></li>
<li><a href="#boxplots"><span class="toc-section-number">3.5</span> Boxplots</a></li>
</ul></li>
<li><a href="#data-description"><span class="toc-section-number">4</span> Data Description</a></li>
<li><a href="#data-preparation"><span class="toc-section-number">5</span> Data Preparation</a></li>
<li><a href="#model-choices"><span class="toc-section-number">6</span> Model Choices</a></li>
<li><a href="#model-preparations"><span class="toc-section-number">7</span> Model Preparations</a></li>
<li><a href="#applying-the-models"><span class="toc-section-number">8</span> Applying the Models</a><ul>
<li><a href="#linear-regression"><span class="toc-section-number">8.1</span> Linear Regression</a></li>
<li><a href="#partial-least-squares"><span class="toc-section-number">8.2</span> Partial Least Squares</a></li>
<li><a href="#principal-component-regression"><span class="toc-section-number">8.3</span> Principal Component Regression</a></li>
<li><a href="#ridge-regression"><span class="toc-section-number">8.4</span> Ridge Regression</a></li>
<li><a href="#lasso-regression"><span class="toc-section-number">8.5</span> Lasso Regression</a></li>
<li><a href="#elestic-net"><span class="toc-section-number">8.6</span> Elestic Net</a></li>
<li><a href="#neural-networks"><span class="toc-section-number">8.7</span> Neural Networks</a></li>
<li><a href="#mars"><span class="toc-section-number">8.8</span> MARS</a></li>
<li><a href="#svm"><span class="toc-section-number">8.9</span> SVM</a></li>
<li><a href="#knn"><span class="toc-section-number">8.10</span> KNN</a></li>
</ul></li>
<li><a href="#model-performances"><span class="toc-section-number">9</span> Model Performances</a></li>
<li><a href="#model-comparison"><span class="toc-section-number">10</span> Model Comparison</a></li>
<li><a href="#final-notes"><span class="toc-section-number">11</span> Final Notes</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This blog post is a comprehensive summary of predictive modeling with regression techniques. It is Inspired by a lecture given by Sandjai Bhulai, Professor at the Free University of Amsterdam and co-founder of the postgraduate programme Business Analytics / Data Science. The main purpose is to have a quick look at the techniques and develop a proper workflow. The blog post also serves as my personal summary of the lecture.</p>
</div>
<div id="packages-and-initialisations" class="section level1">
<h1><span class="header-section-number">2</span> Packages and initialisations</h1>
<pre class="r"><code>knitr::opts_chunk$set(echo = T, eval = T, warning = F, message = F, cache = T,
                      fig.align = &quot;center&quot;, fig.width = 7, fig.height = 7)

## Load packages &amp; Install if necessary
ipak &lt;- function(pkg) {
  new.pkg &lt;- pkg[!(pkg %in% installed.packages()[, &quot;Package&quot;])]
  if (length(new.pkg))
  install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}


packages &lt;- c(&quot;data.table&quot;, &quot;ggthemes&quot;, &quot;tidyverse&quot;, &quot;DataExplorer&quot;, &quot;kableExtra&quot;, &quot;knitr&quot;, &quot;data.table&quot;
              ,&quot;readr&quot;, &quot;RColorBrewer&quot;, &quot;htmlwidgets&quot;, &quot;htmltools&quot;, &quot;widgetframe&quot;, &quot;highcharter&quot;, &quot;elasticnet&quot;, &quot;here&quot;)

ipak(packages)</code></pre>
<pre><code>##   data.table     ggthemes    tidyverse DataExplorer   kableExtra 
##         TRUE         TRUE         TRUE         TRUE         TRUE 
##        knitr   data.table        readr RColorBrewer  htmlwidgets 
##         TRUE         TRUE         TRUE         TRUE         TRUE 
##    htmltools  widgetframe  highcharter   elasticnet         here 
##         TRUE         TRUE         TRUE         TRUE         TRUE</code></pre>
<pre class="r"><code>theme_set(theme_few()) # add few theme to plots</code></pre>
</div>
<div id="exploratory-data-analysis-eda" class="section level1">
<h1><span class="header-section-number">3</span> Exploratory Data Analysis (EDA)</h1>
<p>Quick look at the data.</p>
<pre class="r"><code>FuelEff &lt;- fread(here(&quot;static&quot;, &quot;data&quot;,&quot;Regressions/FuelEfficiency.csv&quot;))

FuelEff$ET &lt;- as.factor(FuelEff$ET)
FuelEff$NC &lt;- as.factor(FuelEff$NC)

glimpse(FuelEff)</code></pre>
<pre><code>## Observations: 38
## Variables: 8
## $ MPG &lt;dbl&gt; 16.9, 15.5, 19.2, 18.5, 30.0, 27.5, 27.2, 30.9, 20.3, 17.0...
## $ GPM &lt;dbl&gt; 5.917, 6.452, 5.208, 5.405, 3.333, 3.636, 3.676, 3.236, 4....
## $ WT  &lt;dbl&gt; 4.360, 4.054, 3.605, 3.940, 2.155, 2.560, 2.300, 2.230, 2....
## $ DIS &lt;int&gt; 350, 351, 267, 360, 98, 134, 119, 105, 131, 163, 121, 163,...
## $ NC  &lt;fct&gt; 8, 8, 8, 8, 4, 4, 4, 4, 5, 6, 4, 6, 6, 6, 6, 6, 8, 8, 8, 8...
## $ HP  &lt;int&gt; 155, 142, 125, 150, 68, 95, 97, 75, 103, 125, 115, 133, 10...
## $ ACC &lt;dbl&gt; 14.9, 14.3, 15.0, 13.0, 16.5, 14.2, 14.7, 14.5, 15.9, 13.6...
## $ ET  &lt;fct&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1...</code></pre>
<p>Below you will find a few descriptive plots of the data, which is important to have before you start with the actual predictions</p>
<div id="missing-values" class="section level2">
<h2><span class="header-section-number">3.1</span> Missing Values</h2>
<p>There are no missing values</p>
<pre class="r"><code>plot_missing(FuelEff)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="discrete-variables" class="section level2">
<h2><span class="header-section-number">3.2</span> Discrete Variables</h2>
<pre class="r"><code>plot_bar(FuelEff, title = &quot;Bar charts of all discrete variables&quot;)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="continuous-variables" class="section level2">
<h2><span class="header-section-number">3.3</span> Continuous Variables</h2>
<pre class="r"><code>plot_histogram(FuelEff, title = &quot;Histograms of all continues variables&quot;)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="correlations" class="section level2">
<h2><span class="header-section-number">3.4</span> Correlations</h2>
<pre class="r"><code>plot_correlation(FuelEff, use = &quot;pairwise.complete.obs&quot;, title = &quot;Correlation Matrix&quot;)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="boxplots" class="section level2">
<h2><span class="header-section-number">3.5</span> Boxplots</h2>
<pre class="r"><code>plot_boxplot(FuelEff, &quot;MPG&quot;, title = &quot;Boxplot of all variables with target variable MPG&quot;)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="data-description" class="section level1">
<h1><span class="header-section-number">4</span> Data Description</h1>
<p>Especially the correlation plots and box plots give a good indication of which variables might be important for your predictions. In this particular case, we see that <code>WT</code>, <code>HP</code> and <code>DIS</code> will likely be strong predictors, while <code>ACC</code> will not have a lot of impact. In larger datasets, there are many more steps to take before we select the eventual features.</p>
</div>
<div id="data-preparation" class="section level1">
<h1><span class="header-section-number">5</span> Data Preparation</h1>
<p>The current example dataset is small and easy to understand. However, it is good practice to perform a multitude of data preparation steps. The following steps are all useful and should always be considered before you start with machine learning.</p>
<ol style="list-style-type: decimal">
<li>Centering &amp; Scaling</li>
<li>Check for skewness
<ul>
<li>Rule of Thumb : (Largest / Smallest) &gt; 20 = significant skewness</li>
<li>Use BoxCox tests to transform predictors and remove the skewness</li>
</ul></li>
<li>Check for outliers
<ul>
<li>Do not just throw away anything you think is an outlier. Think about the implications!</li>
<li>Be careful with sampling your dataset - outliers might not be outliers at all.</li>
<li>Check with experts about the collected data, they might know the reason for outliers.</li>
</ul></li>
<li>Data reduction &amp; feature extraction
<ul>
<li>Not a big issue in small datasets. But for large datasets, it will massively increase performance, and often have better results too.</li>
<li>PCA is a great technique to use.</li>
</ul></li>
<li>Dealing with missing values
<ul>
<li>Check for structurally missign values (might be mistakes in data collection, or surveys)</li>
<li>Missing data might be informative!</li>
<li>Data might be censored</li>
<li>Imputate missing values. Choose appropriate methods.
<ul>
<li>Using the data (mean, median)</li>
<li>Random Draw</li>
<li>Remove the samples</li>
<li>Remove predictor (if large % missing)</li>
<li>PCA to detect correlations</li>
<li>KNN to fill in according to neighbouring values</li>
</ul></li>
</ul></li>
<li>Removing predictors
<ul>
<li>Remove predictors with near-zero variance</li>
<li>Remove multicollinearity</li>
</ul></li>
<li>Adding predictors
<ul>
<li>Higher-order predictors might increase performance</li>
<li>Dummy variables for categorical data</li>
</ul></li>
<li>Binning variables
<ul>
<li>Do not do this manually!</li>
</ul></li>
</ol>
</div>
<div id="model-choices" class="section level1">
<h1><span class="header-section-number">6</span> Model Choices</h1>
<p>Choosing a model is not straightforward. There is a large variety of models, where each model excels at different things.</p>
<ul>
<li><p>Generally speaking, the best practice is to start with several models that are the <em>least</em> interpretable and most <em>flexible</em>, such as <a href="https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting"><code>Boosted Trees</code></a> or <a href="https://en.wikipedia.org/wiki/Support_vector_machine"><code>Support Vector Machines (SVM)</code></a>. These models generally produce the most optimum results among a wide variety of predictions.</p></li>
<li><p>It is then adviced to investigate simpler, less opaque, models, such as <a href="https://en.wikipedia.org/wiki/Partial_least_squares_regression"><code>Patial Least Squares (PLS)</code></a>, <a href="https://en.wikipedia.org/wiki/Generalized_additive_model"><code>Generalized Additive Models (GAM)</code></a> or <a href="https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines"><code>Multivariate Addeptive Regression Splines (MARS)</code></a>.</p></li>
<li><p>Use the simplest model that reasonably approximates the performance of the more complex methods - unless the complexity is not an issue (which is rarely the case).</p></li>
</ul>
<p>See the image below for a quick summary of regression techniques.</p>
<center>
<img src="http://res.cloudinary.com/stefanmusch/image/upload/v1518948409/Regression_Summary.png" alt="Regression Techniques Summary" />
</center>
</div>
<div id="model-preparations" class="section level1">
<h1><span class="header-section-number">7</span> Model Preparations</h1>
<p>Each model requires different parameters. Tuning these parameters is extremely important for your model performances. The image above shows the complexity of tuning the parameters (e.g. 0 is easy, 2 is hard) for each model. Wrong parameters can easily lead to <code>bias</code>, <code>variance</code> or <code>overfitting</code> of your model.</p>
<p>To reduce these issues, a variety of techniques for training your data can be used. The most common ones are <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)"><code>Cross-Validation (CV)</code></a> and <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation"><code>Leave One Out Cross Validation (LOOCV)</code></a>.</p>
<p>In R, the easiest way to train models, and set control parameters is with the package <a href="http://topepo.github.io/caret/index.html"><code>Caret</code></a>. Which is what I will be using as well.</p>
<pre class="r"><code>library(caret)
FuelEff &lt;- fread(here(&quot;static&quot;, &quot;data&quot;, &quot;Regressions/FuelEfficiency.csv&quot;))
FuelEff &lt;- FuelEff[, -1] %&gt;%
  as.data.frame()

#ctrl &lt;- trainControl(method = &quot;LOOCV&quot;)
ctrl &lt;- trainControl(method = &quot;cv&quot;, number = 10)

traindata &lt;- FuelEff[, 2:7]
response &lt;- FuelEff[, 1]</code></pre>
</div>
<div id="applying-the-models" class="section level1 tabset tabset-fade">
<h1><span class="header-section-number">8</span> Applying the Models</h1>
<p>It is important to set the same seed for each model, so we can 1) compare the models on the same data, and 2) reproduce the same results.</p>
<div id="linear-regression" class="section level2">
<h2><span class="header-section-number">8.1</span> Linear Regression</h2>
<pre class="r"><code>set.seed(123) 
lmFit &lt;- train(x = traindata, 
               y = response,
               method = &quot;lm&quot;, 
               preProc = c(&quot;center&quot;, &quot;scale&quot;), 
               trControl = ctrl)
lmFit</code></pre>
<pre><code>## Linear Regression 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results:
## 
##   RMSE       Rsquared   MAE      
##   0.3491038  0.9187413  0.2965739
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
</div>
<div id="partial-least-squares" class="section level2">
<h2><span class="header-section-number">8.2</span> Partial Least Squares</h2>
<pre class="r"><code>set.seed(123)
plsFit &lt;-
  train(x = traindata,
        y = response,
        method = &quot;pls&quot;,
        preProc = c(&quot;center&quot;, &quot;scale&quot;),
        trControl = ctrl)
plsFit</code></pre>
<pre><code>## Partial Least Squares 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   ncomp  RMSE       Rsquared   MAE      
##   1      0.5342822  0.8222915  0.4320590
##   2      0.4340009  0.8679883  0.3488201
##   3      0.3860258  0.9311885  0.3216491
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was ncomp = 3.</code></pre>
<pre class="r"><code>plot(plsFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="principal-component-regression" class="section level2">
<h2><span class="header-section-number">8.3</span> Principal Component Regression</h2>
<pre class="r"><code>set.seed(123)
pcrFit &lt;-
  train(x = traindata,
        y = response,
        method = &quot;pcr&quot;,
        preProc = c(&quot;center&quot;, &quot;scale&quot;),
        trControl = ctrl)
pcrFit</code></pre>
<pre><code>## Principal Component Analysis 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   ncomp  RMSE       Rsquared   MAE      
##   1      0.5901381  0.8066295  0.4767139
##   2      0.5190486  0.8306519  0.4254869
##   3      0.4124337  0.9203584  0.3402541
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was ncomp = 3.</code></pre>
<pre class="r"><code>plot(pcrFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="ridge-regression" class="section level2">
<h2><span class="header-section-number">8.4</span> Ridge Regression</h2>
<pre class="r"><code>set.seed(123)
ridgeGrid &lt;-
  data.frame(.lambda = seq(0, .1, length = 15)) #Lambda definitie

ridgeFit &lt;-
  train(
    x = traindata,
    y = response,
    method = &quot;ridge&quot;,
    preProc = c(&quot;center&quot;, &quot;scale&quot;),
    tuneGrid = ridgeGrid,
    trControl = ctrl
  )
ridgeFit</code></pre>
<pre><code>## Ridge Regression 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   lambda       RMSE       Rsquared   MAE      
##   0.000000000  0.3491038  0.9187413  0.2965739
##   0.007142857  0.3491084  0.9202143  0.3001565
##   0.014285714  0.3507518  0.9207730  0.3028851
##   0.021428571  0.3529498  0.9206881  0.3051401
##   0.028571429  0.3552928  0.9201613  0.3070819
##   0.035714286  0.3576155  0.9193276  0.3088000
##   0.042857143  0.3598528  0.9182768  0.3103513
##   0.050000000  0.3619842  0.9170698  0.3117746
##   0.057142857  0.3640082  0.9157489  0.3130972
##   0.064285714  0.3659322  0.9143445  0.3143393
##   0.071428571  0.3677669  0.9128791  0.3155160
##   0.078571429  0.3695238  0.9113699  0.3166387
##   0.085714286  0.3712140  0.9098305  0.3179670
##   0.092857143  0.3728477  0.9082714  0.3196433
##   0.100000000  0.3744343  0.9067017  0.3212299
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was lambda = 0.</code></pre>
<pre class="r"><code>plot(ridgeFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="lasso-regression" class="section level2">
<h2><span class="header-section-number">8.5</span> Lasso Regression</h2>
<pre class="r"><code>set.seed(123)
lassoGrid &lt;- data.frame(.fraction = seq(0.05, 1, length = 20))
lassoFit &lt;-
  train(
    x = traindata,
    y = response,
    method = &quot;lars&quot;,
    preProc = c(&quot;center&quot;, &quot;scale&quot;),
    tuneGrid = lassoGrid,
    trControl = ctrl
  )
lassoFit</code></pre>
<pre><code>## Least Angle Regression 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   fraction  RMSE       Rsquared   MAE      
##   0.05      0.9914435  0.8821032  0.9225322
##   0.10      0.8691388  0.8810176  0.8078626
##   0.15      0.7524983  0.8757677  0.6955019
##   0.20      0.6419761  0.8694007  0.5849300
##   0.25      0.5404261  0.8626244  0.4768875
##   0.30      0.4534510  0.8572930  0.3876725
##   0.35      0.4148866  0.8568022  0.3519432
##   0.40      0.4124938  0.8648776  0.3544209
##   0.45      0.4083596  0.8716531  0.3480199
##   0.50      0.3990464  0.8835669  0.3377982
##   0.55      0.3878828  0.8953990  0.3266916
##   0.60      0.3787880  0.9038286  0.3201525
##   0.65      0.3723993  0.9092132  0.3172129
##   0.70      0.3697524  0.9126979  0.3165587
##   0.75      0.3688900  0.9130463  0.3163729
##   0.80      0.3658178  0.9142300  0.3145681
##   0.85      0.3603385  0.9158821  0.3102977
##   0.90      0.3554954  0.9171826  0.3057231
##   0.95      0.3517300  0.9181306  0.3011485
##   1.00      0.3491038  0.9187413  0.2965739
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was fraction = 1.</code></pre>
<pre class="r"><code>plot(lassoFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="elestic-net" class="section level2">
<h2><span class="header-section-number">8.6</span> Elestic Net</h2>
<pre class="r"><code>set.seed(123)
enetGrid &lt;-
  expand.grid(.lambda = c(0, 0.01, .1),
              .fraction = seq(.05, 1, length = 20))
enetFit &lt;-
  train(
    x = traindata,
    y = response,
    method = &quot;enet&quot;,
    preProc = c(&quot;center&quot;, &quot;scale&quot;),
    tuneGrid = enetGrid,
    trControl = ctrl
  )
enetFit</code></pre>
<pre><code>## Elasticnet 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   lambda  fraction  RMSE       Rsquared   MAE      
##   0.00    0.05      0.9914435  0.8821032  0.9225322
##   0.00    0.10      0.8691388  0.8810176  0.8078626
##   0.00    0.15      0.7524983  0.8757677  0.6955019
##   0.00    0.20      0.6419761  0.8694007  0.5849300
##   0.00    0.25      0.5404261  0.8626244  0.4768875
##   0.00    0.30      0.4534510  0.8572930  0.3876725
##   0.00    0.35      0.4148866  0.8568022  0.3519432
##   0.00    0.40      0.4124938  0.8648776  0.3544209
##   0.00    0.45      0.4083596  0.8716531  0.3480199
##   0.00    0.50      0.3990464  0.8835669  0.3377982
##   0.00    0.55      0.3878828  0.8953990  0.3266916
##   0.00    0.60      0.3787880  0.9038286  0.3201525
##   0.00    0.65      0.3723993  0.9092132  0.3172129
##   0.00    0.70      0.3697524  0.9126979  0.3165587
##   0.00    0.75      0.3688900  0.9130463  0.3163729
##   0.00    0.80      0.3658178  0.9142300  0.3145681
##   0.00    0.85      0.3603385  0.9158821  0.3102977
##   0.00    0.90      0.3554954  0.9171826  0.3057231
##   0.00    0.95      0.3517300  0.9181306  0.3011485
##   0.00    1.00      0.3491038  0.9187413  0.2965739
##   0.01    0.05      1.0021737  0.8821032  0.9324097
##   0.01    0.10      0.8901040  0.8809871  0.8275808
##   0.01    0.15      0.7826987  0.8755224  0.7249137
##   0.01    0.20      0.6800796  0.8690532  0.6238765
##   0.01    0.25      0.5838516  0.8619770  0.5250596
##   0.01    0.30      0.4958268  0.8564919  0.4316494
##   0.01    0.35      0.4352548  0.8531532  0.3672571
##   0.01    0.40      0.4194547  0.8543208  0.3586732
##   0.01    0.45      0.4155285  0.8571756  0.3554100
##   0.01    0.50      0.4102322  0.8658767  0.3483506
##   0.01    0.55      0.3993022  0.8799371  0.3382498
##   0.01    0.60      0.3885199  0.8924834  0.3283067
##   0.01    0.65      0.3796402  0.9021405  0.3202953
##   0.01    0.70      0.3733477  0.9089035  0.3171051
##   0.01    0.75      0.3690766  0.9142236  0.3137839
##   0.01    0.80      0.3674409  0.9153729  0.3138569
##   0.01    0.85      0.3629853  0.9170631  0.3116112
##   0.01    0.90      0.3577906  0.9185066  0.3081810
##   0.01    0.95      0.3533306  0.9196578  0.3047508
##   0.01    1.00      0.3496541  0.9205312  0.3013206
##   0.10    0.05      1.0332806  0.8821032  0.9609821
##   0.10    0.10      0.9518415  0.8783502  0.8851119
##   0.10    0.15      0.8730545  0.8683000  0.8111682
##   0.10    0.20      0.7970407  0.8584787  0.7389782
##   0.10    0.25      0.7212938  0.8522060  0.6655895
##   0.10    0.30      0.6481007  0.8480263  0.5928386
##   0.10    0.35      0.5794113  0.8406220  0.5233410
##   0.10    0.40      0.5197609  0.8340106  0.4600211
##   0.10    0.45      0.4755120  0.8299935  0.4080893
##   0.10    0.50      0.4467121  0.8286540  0.3800511
##   0.10    0.55      0.4357717  0.8289656  0.3667490
##   0.10    0.60      0.4249146  0.8361190  0.3558767
##   0.10    0.65      0.4160983  0.8441368  0.3477751
##   0.10    0.70      0.4096045  0.8512172  0.3433161
##   0.10    0.75      0.3997441  0.8615736  0.3378336
##   0.10    0.80      0.3912180  0.8721311  0.3327923
##   0.10    0.85      0.3843666  0.8822711  0.3287078
##   0.10    0.90      0.3789450  0.8916914  0.3249573
##   0.10    0.95      0.3756573  0.8998559  0.3229113
##   0.10    1.00      0.3744343  0.9067017  0.3212299
## 
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were fraction = 1 and lambda = 0.</code></pre>
<pre class="r"><code>plot(enetFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="neural-networks" class="section level2">
<h2><span class="header-section-number">8.7</span> Neural Networks</h2>
<p><strong>Parameters</strong></p>
<ul>
<li>Decay - sensitivity of the parameters. Used to balance overfitting / bias.</li>
<li>Size - How many units the hidden layer has</li>
<li>Bagging - Trying multiple neural networks and averaging these</li>
<li>Linout - Linear output. Should be FALSE if doing classification instead of regression</li>
<li>Trace - Shows everything that the model is doing - increases time</li>
<li>maxNWts - Makes sure that you have enough memory to calculate the networks. If not - it won’t run.</li>
<li>maxit - Maximum number of iterations before it stops, even if the network is not optimal yet.</li>
</ul>
<pre class="r"><code>set.seed(123)
nnetGrid &lt;-
  expand.grid(.decay = c(0, 0.01, .1),
              .size = c(1:10),
              .bag = FALSE)
nnetFit &lt;-
  train(
    traindata,
    response,
    method = &quot;avNNet&quot;,
    tuneGrid = nnetGrid,
    trControl = ctrl,
    linout = TRUE,
    trace = FALSE,
    MaxNWts = 10 * (ncol(traindata) + 1) + 10 + 1,
    maxit = 500,
    preProc = c(&quot;center&quot;, &quot;scale&quot;)
  )
nnetFit</code></pre>
<pre><code>## Model Averaged Neural Network 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   decay  size  RMSE       Rsquared   MAE      
##   0.00    1    0.3895405  0.8973923  0.3323903
##   0.00    2    0.6569133  0.8374466  0.5035775
##   0.00    3    0.6826297  0.8788383  0.5424810
##   0.00    4    0.8463658  0.6359670  0.6789124
##   0.00    5    0.7656605  0.7740208  0.6511560
##   0.00    6    0.8698821  0.7202164  0.7354869
##   0.00    7    1.0796775  0.6358712  0.8771279
##   0.00    8    1.0075220  0.6479410  0.8434621
##   0.00    9    0.8636968  0.7044664  0.7012957
##   0.00   10    0.9540263  0.6683322  0.7794921
##   0.01    1    0.3526006  0.9128624  0.3057678
##   0.01    2    0.3619619  0.9298032  0.3098504
##   0.01    3    0.3683206  0.9048323  0.3179104
##   0.01    4    0.3941588  0.9332994  0.3447662
##   0.01    5    0.4137627  0.9199535  0.3668975
##   0.01    6    0.4464267  0.8694082  0.3935072
##   0.01    7    0.4669006  0.8531353  0.4122863
##   0.01    8    0.4569140  0.8535870  0.4078636
##   0.01    9    0.4561972  0.8515777  0.4056808
##   0.01   10    0.4445728  0.8499994  0.3852996
##   0.10    1    0.3335752  0.9203501  0.2862332
##   0.10    2    0.3416498  0.9193257  0.2975506
##   0.10    3    0.3675403  0.9102944  0.3178251
##   0.10    4    0.3619042  0.9101573  0.3132779
##   0.10    5    0.3625173  0.9124789  0.3154598
##   0.10    6    0.3646521  0.9138108  0.3179842
##   0.10    7    0.3624660  0.9132400  0.3147886
##   0.10    8    0.3619679  0.9140112  0.3139177
##   0.10    9    0.3613569  0.9142954  0.3127367
##   0.10   10    0.3638330  0.9143804  0.3153601
## 
## Tuning parameter &#39;bag&#39; was held constant at a value of FALSE
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were size = 1, decay = 0.1 and bag
##  = FALSE.</code></pre>
</div>
<div id="mars" class="section level2">
<h2><span class="header-section-number">8.8</span> MARS</h2>
<p><strong>Parameters</strong></p>
<ul>
<li>Pruning - Complexity degree of your model</li>
</ul>
<pre class="r"><code>set.seed(123)
marsGrid &lt;- expand.grid(.degree = 1:2, .nprune = 2:38)
marsFit &lt;-
  train(
    traindata,
    response,
    method = &quot;earth&quot;,
    tuneGrid = marsGrid,
    trControl = ctrl
  )
marsFit</code></pre>
<pre><code>## Multivariate Adaptive Regression Spline 
## 
## 38 samples
##  6 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   degree  nprune  RMSE       Rsquared   MAE      
##   1        2      0.4839472  0.8753910  0.4147103
##   1        3      0.5227159  0.8259529  0.4237267
##   1        4      0.4176467  0.8780799  0.3421071
##   1        5      0.4208958  0.8701870  0.3751769
##   1        6      0.4182763  0.8645150  0.3776940
##   1        7      0.4347006  0.8497555  0.3939607
##   1        8      0.4349547  0.8440440  0.3936475
##   1        9      0.4248572  0.8388525  0.3793411
##   1       10      0.4248572  0.8388525  0.3793411
##   1       11      0.4248572  0.8388525  0.3793411
##   1       12      0.4248572  0.8388525  0.3793411
##   1       13      0.4248572  0.8388525  0.3793411
##   1       14      0.4248572  0.8388525  0.3793411
##   1       15      0.4248572  0.8388525  0.3793411
##   1       16      0.4248572  0.8388525  0.3793411
##   1       17      0.4248572  0.8388525  0.3793411
##   1       18      0.4248572  0.8388525  0.3793411
##   1       19      0.4248572  0.8388525  0.3793411
##   1       20      0.4248572  0.8388525  0.3793411
##   1       21      0.4248572  0.8388525  0.3793411
##   1       22      0.4248572  0.8388525  0.3793411
##   1       23      0.4248572  0.8388525  0.3793411
##   1       24      0.4248572  0.8388525  0.3793411
##   1       25      0.4248572  0.8388525  0.3793411
##   1       26      0.4248572  0.8388525  0.3793411
##   1       27      0.4248572  0.8388525  0.3793411
##   1       28      0.4248572  0.8388525  0.3793411
##   1       29      0.4248572  0.8388525  0.3793411
##   1       30      0.4248572  0.8388525  0.3793411
##   1       31      0.4248572  0.8388525  0.3793411
##   1       32      0.4248572  0.8388525  0.3793411
##   1       33      0.4248572  0.8388525  0.3793411
##   1       34      0.4248572  0.8388525  0.3793411
##   1       35      0.4248572  0.8388525  0.3793411
##   1       36      0.4248572  0.8388525  0.3793411
##   1       37      0.4248572  0.8388525  0.3793411
##   1       38      0.4248572  0.8388525  0.3793411
##   2        2      0.4034104  0.8986415  0.3360562
##   2        3      0.4025746  0.8919200  0.3420545
##   2        4      0.3694814  0.8981198  0.3210576
##   2        5      0.3805058  0.8899355  0.3317454
##   2        6      0.3907333  0.8676445  0.3382646
##   2        7      0.3907333  0.8676445  0.3382646
##   2        8      0.3907333  0.8676445  0.3382646
##   2        9      0.3907333  0.8676445  0.3382646
##   2       10      0.3907333  0.8676445  0.3382646
##   2       11      0.3907333  0.8676445  0.3382646
##   2       12      0.3907333  0.8676445  0.3382646
##   2       13      0.3907333  0.8676445  0.3382646
##   2       14      0.3907333  0.8676445  0.3382646
##   2       15      0.3907333  0.8676445  0.3382646
##   2       16      0.3907333  0.8676445  0.3382646
##   2       17      0.3907333  0.8676445  0.3382646
##   2       18      0.3907333  0.8676445  0.3382646
##   2       19      0.3907333  0.8676445  0.3382646
##   2       20      0.3907333  0.8676445  0.3382646
##   2       21      0.3907333  0.8676445  0.3382646
##   2       22      0.3907333  0.8676445  0.3382646
##   2       23      0.3907333  0.8676445  0.3382646
##   2       24      0.3907333  0.8676445  0.3382646
##   2       25      0.3907333  0.8676445  0.3382646
##   2       26      0.3907333  0.8676445  0.3382646
##   2       27      0.3907333  0.8676445  0.3382646
##   2       28      0.3907333  0.8676445  0.3382646
##   2       29      0.3907333  0.8676445  0.3382646
##   2       30      0.3907333  0.8676445  0.3382646
##   2       31      0.3907333  0.8676445  0.3382646
##   2       32      0.3907333  0.8676445  0.3382646
##   2       33      0.3907333  0.8676445  0.3382646
##   2       34      0.3907333  0.8676445  0.3382646
##   2       35      0.3907333  0.8676445  0.3382646
##   2       36      0.3907333  0.8676445  0.3382646
##   2       37      0.3907333  0.8676445  0.3382646
##   2       38      0.3907333  0.8676445  0.3382646
## 
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were nprune = 4 and degree = 2.</code></pre>
<pre class="r"><code>plot(marsFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="svm" class="section level2">
<h2><span class="header-section-number">8.9</span> SVM</h2>
<p><strong>Parameters</strong></p>
<ul>
<li>Can be either Radial / Polynomial / Linear</li>
<li>Tunelength - Complexity</li>
</ul>
<pre class="r"><code>set.seed(123)
svmFit &lt;-
  train(
    traindata,
    response,
    method = &quot;svmRadial&quot;,
    tuneLength = 14,
    preProc = c(&quot;center&quot;, &quot;scale&quot;),
    trControl = ctrl
  )
svmFit</code></pre>
<pre><code>## Support Vector Machines with Radial Basis Function Kernel 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   C        RMSE       Rsquared   MAE      
##      0.25  0.5919977  0.8378634  0.4865879
##      0.50  0.5236983  0.8676116  0.4471119
##      1.00  0.4691761  0.8957120  0.4029897
##      2.00  0.4564244  0.8537364  0.3931610
##      4.00  0.4563069  0.8448426  0.3945761
##      8.00  0.4660388  0.8455530  0.4041276
##     16.00  0.4733663  0.8418228  0.4093908
##     32.00  0.4728235  0.8409826  0.3994785
##     64.00  0.4903507  0.8238986  0.4114824
##    128.00  0.4907464  0.8235286  0.4118808
##    256.00  0.4907464  0.8235286  0.4118808
##    512.00  0.4907464  0.8235286  0.4118808
##   1024.00  0.4907464  0.8235286  0.4118808
##   2048.00  0.4907464  0.8235286  0.4118808
## 
## Tuning parameter &#39;sigma&#39; was held constant at a value of 0.4731597
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were sigma = 0.4731597 and C = 4.</code></pre>
<pre class="r"><code>plot(svmFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="knn" class="section level2">
<h2><span class="header-section-number">8.10</span> KNN</h2>
<pre class="r"><code>set.seed(123)
knnFit &lt;-
  train(
    traindata,
    response,
    method = &quot;knn&quot;,
    preProc = c(&quot;center&quot;, &quot;scale&quot;),
    tuneGrid = data.frame(.k = 1:20),
    trControl = ctrl
  )
knnFit</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 38 samples
##  6 predictor
## 
## Pre-processing: centered (6), scaled (6) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 34, 35, 35, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   k   RMSE       Rsquared   MAE      
##    1  0.5414309  0.8170529  0.4652833
##    2  0.4698088  0.8428303  0.3928792
##    3  0.4989522  0.8224664  0.4212111
##    4  0.5056929  0.8219990  0.4109583
##    5  0.4905562  0.8513589  0.4127183
##    6  0.5027853  0.8368725  0.4288778
##    7  0.4926643  0.8435061  0.4278321
##    8  0.4883420  0.8315829  0.4261365
##    9  0.5170485  0.8297113  0.4485491
##   10  0.5324021  0.8230479  0.4611917
##   11  0.5519344  0.8178468  0.4777818
##   12  0.5572327  0.8253967  0.4820764
##   13  0.5587074  0.8345198  0.4788077
##   14  0.5869497  0.8309002  0.4998607
##   15  0.5949151  0.8369644  0.5142122
##   16  0.6090828  0.8410554  0.5257927
##   17  0.6261019  0.8322213  0.5506176
##   18  0.6560881  0.8039646  0.5795620
##   19  0.6904664  0.7902431  0.6047368
##   20  0.7291519  0.7881980  0.6467608
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was k = 2.</code></pre>
<pre class="r"><code>plot(knnFit)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="model-performances" class="section level1">
<h1><span class="header-section-number">9</span> Model Performances</h1>
<p>Evaluating performances of your model can be done by calculating a few statistical properties of the model and its predictions.</p>
<ol style="list-style-type: decimal">
<li>Mean Absolute Error (MEA)
<ul>
<li>Absolute difference between observed values and the model predictions</li>
</ul></li>
<li>Root Mean Squared Error (RMSE)
<ul>
<li>Average distance between the observed values and the model predictions</li>
</ul></li>
<li>R²
<ul>
<li>Proportion of information in the data that is explained by the model</li>
<li>Is a <em>correlation</em> measure, not accuracy.</li>
</ul></li>
</ol>
</div>
<div id="model-comparison" class="section level1">
<h1><span class="header-section-number">10</span> Model Comparison</h1>
<pre class="r"><code>allResamples &lt;- resamples(
  list(
    &quot;Linear Reg&quot; = lmFit,
    &quot;PLS&quot; = plsFit,
    &quot;PCR&quot; = pcrFit,
    &quot;Ridge&quot; = ridgeFit,
    &quot;LASSO&quot; = lassoFit,
    &quot;Elastic Net&quot; = enetFit,
    &quot;Neural Net&quot; = nnetFit,
    &quot;MARS&quot; = marsFit,
    &quot;SVM&quot; = svmFit,
    &quot;KNN&quot; = knnFit
  )
)

gridExtra::grid.arrange(
parallelplot(allResamples, metric = &quot;RMSE&quot;, main = &quot;RMSE of each fold for each model&quot;),
parallelplot(allResamples, metric = &quot;Rsquared&quot;, main = &quot;R² of each fold for each model&quot;),
ncol = 2)</code></pre>
<p><img src="/post/2018-02-14-predictive-modeling-regression-summary_files/figure-html/unnamed-chunk-18-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="final-notes" class="section level1">
<h1><span class="header-section-number">11</span> Final Notes</h1>
<p>In the end, the final model that you choose to work with depends on a few factors. According to the summary, we should always choose a <code>neural network</code> in this particular example dataset. It is consistant throughout each fold, and gives very accurate predictions. However - it is harder to interpret and it takes up a lot more time than the other models.</p>
<p>For this reason, we might also select the next best things, i.e. <code>Ridge Regression</code>, <code>Lasso</code>, <code>Elastic Net</code> or even <code>Linear Regression</code>. These models are less consistent, yet still perform well, require a lot less time and are far easier to understand, explain and comprehend for every party (think clients, managers etc.) involved.</p>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="/tags/data-analysis/">Data Analysis</a>

  <a class="tag tag--primary tag--small" href="/tags/machine-learning/">Machine Learning</a>

  <a class="tag tag--primary tag--small" href="/tags/regression/">Regression</a>

  <a class="tag tag--primary tag--small" href="/tags/predictive-modeling/">Predictive Modeling</a>

  <a class="tag tag--primary tag--small" href="/tags/neural-network/">Neural Network</a>

  <a class="tag tag--primary tag--small" href="/tags/svm/">SVM</a>

  <a class="tag tag--primary tag--small" href="/tags/knn/">KNN</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/02/creating-your-own-beautiful-holiday-poster/" data-tooltip="Creating your own beautiful holiday poster!">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2017/12/how-jolly-are-christmas-songs-actually/" data-tooltip="How Jolly are Christmas Songs Actually?">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/02/predictive-modeling-regression-summary/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/02/predictive-modeling-regression-summary/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/02/predictive-modeling-regression-summary/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Stefan Musch. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/02/creating-your-own-beautiful-holiday-poster/" data-tooltip="Creating your own beautiful holiday poster!">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2017/12/how-jolly-are-christmas-songs-actually/" data-tooltip="How Jolly are Christmas Songs Actually?">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2018/02/predictive-modeling-regression-summary/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2018/02/predictive-modeling-regression-summary/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2018/02/predictive-modeling-regression-summary/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2018%2F02%2Fpredictive-modeling-regression-summary%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2018%2F02%2Fpredictive-modeling-regression-summary%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2018%2F02%2Fpredictive-modeling-regression-summary%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="http://res.cloudinary.com/stefanmusch/image/upload/c_scale,w_725/v1534148918/thumbnail/headshot2.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Stefan Musch</h4>
    
      <div id="about-card-bio">Data Scientist | Marketing Analyst |<br> Music, Sports &amp; Adventure Enthousiast <br> <br> This blog is the place where I share my work, projects, frustrations and discoveries. I designed it to be entertaining to some, and educative to others. Sometimes hopefully both. <br><br>Enjoy reading, and feel free to leave a comment!</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        &#39;s-Hertogenbosch, NL
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/02/advanced-marketing-analytics/">
                <h3 class="media-heading">Advanced Marketing Analytics</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">What I’ve been up toThis blog has been quiet for almost a year now. Mostly because I joined a Marketing Analytics company called Gradient Metrics as an all-round quantitative analyst. Gradient gave me the opportunity to combine my previous marketing experience with my newfound love for data science, and I never looked back.
Combining Marketing &amp; Data ScienceA successful marketing strategy will always require two dimensions. On one end, you’ll find creativity.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/an-awesome-spotify-playlist-analysis/">
                <h3 class="media-heading">An Awesome Spotify Playlist Analysis</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Together with a couple of friends, we’ve created our own personal Awesome Mix Vol.1Instead of being a tape with 13 songs however, we’ve added roughly 1.500 songs. Now I’m curious as to how our musical taste differs from one another, but also what kind of musical clusters we have created in our playlist.
Let’s get started.## Rspotify spotifyr tidyverse knitr kableExtra ggthemes ## TRUE TRUE TRUE TRUE TRUE TRUE ## highcharter htmltools widgetframe cluster factoextra here ## TRUE TRUE TRUE TRUE TRUE TRUEFirst, I’ll have to extract the audio features of each song in the playlist.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/02/creating-your-own-beautiful-holiday-poster/">
                <h3 class="media-heading">Creating your own beautiful holiday poster!</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">IntroductionI love traveling, and I love world maps, even more so when I can hang them on my walls. Now that got me thinking. What if I could create maps, with a similar look and feel, of all my holiday destinations? And what if I plot my location progression on top of the destination? That would be absolutely awesome!
In a recent post, I described how Google often tracks your location (if you agreed to it), and plotted each of my tracked location on a map.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/02/predictive-modeling-regression-summary/">
                <h3 class="media-heading">Predictive Modeling - Regression Summary</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">1 Introduction2 Packages and initialisations3 Exploratory Data Analysis (EDA)3.1 Missing Values3.2 Discrete Variables3.3 Continuous Variables3.4 Correlations3.5 Boxplots4 Data Description5 Data Preparation6 Model Choices7 Model Preparations8 Applying the Models8.1 Linear Regression8.2 Partial Least Squares8.3 Principal Component Regression8.4 Ridge Regression8.5 Lasso Regression8.6 Elestic Net8.7 Neural Networks8.8 MARS8.9 SVM8.10 KNN9 Model Performances10 Model Comparison11 Final Notes1 IntroductionThis blog post is a comprehensive summary of predictive modeling with regression techniques.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/12/how-jolly-are-christmas-songs-actually/">
                <h3 class="media-heading">How Jolly are Christmas Songs Actually?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Web ScrapingRequired librariesList of SongsLyrics of the SongsText AnalysisTop 15 wordsChristmas Carol SentimentsPositive vs NegativeMost Positive &amp; Most Negative Christmas CarolChristmas is almost here, and we’ve been hearing a ton of christmas carols and chrismas songs. Now my question is, how jolly are these songs actually? This is a nice opportunity to train my Web Scraping &amp; Text Mining skills.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/12/reading-excel-files-tips-tricks/">
                <h3 class="media-heading">Reading Excel &amp; SPSS Files in R |  Tips &amp; Tricks</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">A Researcher’s Love for Excel and SPSSWorking for the research department at the municipality of Rotterdam (OBI), I discovered their love for excel spread sheets and SPSS documents. Hundreds, no, thousands of them. Each file additionally has another 100 sheets. Sometimes, I needed to join sheets, or bind columns and rows, which is tedious in excel itself. I started scouring packages and functions to find what I needed. In this post, you’ll find some tips and tricks that helped me speed things up.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/11/dutch-housing-situation-rotterdam/">
                <h3 class="media-heading">Dutch Housing Situation - Rotterdam</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Loading LibrariesData WranglingHouse Prices over time - NetherlandsNetherlandsRotterdamRotterdam Vs. NetherlandsAs a Data Science Trainee for the municipality of Rotterdam, I was tasked to find out-of-the-box data sources to measure economic growth within the city. Naturally, I turned towards online estate agents. Funda and Jaap.nl are the biggest players in the Netherlands. Fortunately for me, Jaap.nl makes aggregated data for each municipality publicly available.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/06/my-tracked-locations/">
                <h3 class="media-heading">My Tracked Locations</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Visualising Google Tracking DataLoading &amp; Cleaning dataStatic VisualisationInteractive VisualisationVisualising Google Tracking DataIn 2016 I let google track my location. Everytime my phone sent an update to google, a new record was created. By adding up records for each longitude and latitude coordinates combination, I was able to recreate the spots where I spent most of my time.
Loading &amp; Cleaning data## Load packages &amp; Install if necessaryipak &lt;- function(pkg) {new.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/06/an-r-blog-introduction/">
                <h3 class="media-heading">My R Blog Introduction!</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">When you’ve written the same code 3 times, write a function
When you’ve given the same in-person advice 3 times, write a blog post
&mdash; David Robinson (@drob) November 9, 2017  My StoryI started learning R for real in the summer of 2017, after graduation for my MSc in Marketing Management. My graduation thesis was all about Recommendation Systems and their impact. I wrote my thesis for a festival application called Appic.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         9 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('http://res.cloudinary.com/stefanmusch/image/upload/v1513248424/cover/Cover3.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>




  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2018\/02\/predictive-modeling-regression-summary\/';
          
            this.page.identifier = '\/2018\/02\/predictive-modeling-regression-summary\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'https-stefanmusch-netlify-com';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

